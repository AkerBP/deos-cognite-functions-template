{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cognite.client import CogniteClient \n",
    "from cognite.client.config import ClientConfig\n",
    "from cognite.client.credentials import OAuthInteractive, OAuthClientCredentials\n",
    "from cognite.client.data_classes import TimeSeries\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TENANT_ID = \"3b7e4170-8348-4aa4-bfae-06a3e1867469\"\n",
    "CDF_CLUSTER = \"api\"\n",
    "CLIENT_NAME = \"akerbp\"\n",
    "CLIENT_ID = \"779f2b3b-b599-401a-96aa-48bd29132a27\"  #Cognite API User access- app registration\n",
    "COGNITE_PROJECT = \"akerbp\"\n",
    "SCOPES = [f\"https://{CDF_CLUSTER}.cognitedata.com/.default\"]\n",
    "\n",
    "AUTHORITY_HOST_URI = \"https://login.microsoftonline.com\"\n",
    "AUTHORITY_URI = AUTHORITY_HOST_URI + \"/\" + TENANT_ID\n",
    "PORT = 53000\n",
    "\n",
    "creds = OAuthInteractive(client_id=CLIENT_ID, authority_url=AUTHORITY_URI, scopes=SCOPES)\n",
    "\n",
    "client_cnf = ClientConfig(client_name=CLIENT_NAME, \n",
    "                base_url=f\"https://{CDF_CLUSTER}.cognitedata.com\", \n",
    "                project=COGNITE_PROJECT, credentials=creds)\n",
    "client = CogniteClient(client_cnf)\n",
    "\n",
    "status = client.iam.token.inspect() #verify your client token and status\n",
    "#print(status)\n",
    "if \"projects\" not in vars(status):\n",
    "    raise Exception(\"Token Error!\")\n",
    "\n",
    "ts_input_name = \"VAL_11-LT-95034A:X.Value\"\n",
    "ts_output_name = \"VAL_11-LT-95034A:X.CDF.D.AVG.LeakValue\"\n",
    "tank_volume = 1400\n",
    "derivative_value_excl = 0.002\n",
    "start_date = datetime(2023, 3, 21, 1, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle(client: CogniteClient, data: dict) -> pd.DataFrame:\n",
    "    \"\"\"Calculate drainage rate per timestamp and per day from tank,\n",
    "    using Lowess filtering on volume percentage data from the tank.\n",
    "    Large positive derivatives of signal are excluded to ignore \n",
    "    human interventions (filling) of tank.\n",
    "    Data of drainage rate helps detecting leakages.\n",
    "\n",
    "    Args:\n",
    "        client (CogniteClient): client used to authenticate cognite session\n",
    "        data (dict): data input to the handle\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: dataframe with drainage rate and trend (derivative)\n",
    "    \"\"\"\n",
    "    # STEP 0: Unfold data\n",
    "    tank_volume = data['tank_volume']\n",
    "    derivative_value_excl = data['derivative_value_excl']\n",
    "    start_date = data['start_date']\n",
    "    end_date = start_date + timedelta(days=data['tot_days'])\n",
    "    ts_input_name = data['ts_input_name']\n",
    "    ts_output_name = data['ts_output_name']\n",
    "    dataset_id = data['dataset_id']\n",
    "\n",
    "    # STEP 1: Load time series from name and aggregate\n",
    "\n",
    "    ts_all = client.time_series.search(name=ts_input_name) # find time series by name\n",
    "    cdf_ext_id = ts_all[0].external_id # extract its external id\n",
    "    df_cdf = client.time_series.data.retrieve(external_id=cdf_ext_id, \n",
    "                                        aggregates=\"average\", \n",
    "                                        granularity=\"1m\", \n",
    "                                        start=start_date, \n",
    "                                        end=end_date) # load time series by external id\n",
    "\n",
    "    df = df_cdf.to_pandas()\n",
    "    df = df.rename(columns = {cdf_ext_id + \"|average\": ts_input_name})\n",
    "\n",
    "    # STEP 2: Filter signal\n",
    "    df['time_sec'] = (df.index - datetime(1970,1,1)).total_seconds() # total seconds elapsed of each data point since 1970\n",
    "    vol_perc = df[ts_input_name]\n",
    "    smooth = lowess(vol_perc, df['time_sec'], is_sorted=True, frac=0.01, it=0)\n",
    "    df_smooth = pd.DataFrame(smooth, columns=[\"time_sec\", \"smooth\"])\n",
    "\n",
    "    df.reset_index(inplace=True)\n",
    "    df = df.rename(columns = {'index':'time_stamp'})\n",
    "    df = pd.merge(df, df_smooth, on='time_sec') # merge smooth signal into origianl dataframe\n",
    "    df.set_index('time_stamp', drop=True, append=False, inplace=True, verify_integrity=False)\n",
    "\n",
    "    # STEP 3: Create new time series\n",
    "    ts_output = client.time_series.create(TimeSeries(name=ts_output_name, external_id=ts_output_name, data_set_id=dataset_id))\n",
    "\n",
    "    # STEP 4: Calculate daily average drainage rate\n",
    "    df[\"derivative\"] = np.gradient(df['smooth'], df[\"time_sec\"]) # Unit: vol_percentage/time [% of tank vol / sec]\n",
    "    # replace when derivative is greater than alfa\n",
    "    derivative_value_excl = data['derivative_value_excl']\n",
    "    df['derivative_excl_filling'] = df[\"derivative\"].apply(lambda x: 0 if x > derivative_value_excl or pd.isna(x) else x)\n",
    "\n",
    "    df.reset_index(inplace=True)\n",
    "    df['Date'] = pd.to_datetime(df['time_stamp']).dt.date\n",
    "    #df['Time'] = pd.to_datetime(df['time_stamp']).dt.time\n",
    "    mean_drainage_day = df.groupby('Date')['derivative_excl_filling'].mean()*tank_volume/100 # avg drainage rate per DAY\n",
    "    #mean_df = pd.DataFrame({'mean_derivative_by_day': mean_drainage_day})\n",
    "    mean_df = pd.DataFrame({ts_output_name: mean_drainage_day}) # Use external ID as column name\n",
    "\n",
    "    new_df = pd.merge(df, mean_df, on=\"Date\")\n",
    "    new_df[\"draining_rate [L/min]\"] = new_df[\"derivative_excl_filling\"]*tank_volume/100 # drainage rate per TIME STAMP\n",
    "\n",
    "    ts_inserted = client.time_series.data.insert_dataframe(mean_df)\n",
    "\n",
    "    return new_df, ts_output, ts_inserted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function\n",
    "func_drainage = client.functions.create(\n",
    "    name=\"avg-drainage-rate\",\n",
    "    function_handle=handle\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call function\n",
    "data_dict = {'start_date':start_date, 'tot_days':25, \n",
    "                'ts_input_name':ts_input_name, 'ts_output_name':ts_output_name,\n",
    "            'derivative_value_excl':derivative_value_excl, 'tank_volume':tank_volume}\n",
    "func_info = {'function_id':'avg-drainage-rate'}\n",
    "\n",
    "call_func_drainage = func_drainage.call(data=data_dict, function_call_info=func_info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firsttask",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
