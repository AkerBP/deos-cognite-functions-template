{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook for deploying Cognite Function\n",
    "\n",
    "Run all cells sequentially until `Experimental` section to deploy your Cognite Function.\n",
    "\n",
    "Modifications are done in `Inputs` section, where you need to supply relevant input parameters as required by instantiation, calculations and deployment of your Cognite Function. The input parameters related to calculations and deployment are stored in `data_dict`. There are two types of input parameters:\n",
    "- A: General parameters required for deployment of any Cognite Function\n",
    "- B: Optional (calculation-specific) parameters used as input to your calculation function. These should enter `data_dict[\"calc_params\"]` as key-value pairs.\n",
    "\n",
    "If your Cognite Function is already instantiated, but you want to set up a new schedule, you can omit calling `generate_cf` and skip straight to calling `deploy_cognite_functions` with a modified `data_dict` of parameters that satisfy your scheduled calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Authentication ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from cognite.client.data_classes import functions\n",
    "from cognite.client.data_classes.functions import FunctionSchedulesList\n",
    "from cognite.client.data_classes.functions import FunctionSchedule\n",
    "\n",
    "from initialize import initialize_client\n",
    "from deploy_cognite_functions import deploy_cognite_functions\n",
    "from generate_cf import generate_cf\n",
    "\n",
    "cdf_env = \"dev\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set limit on function calls - don't think it's really necessary ...\n",
    "func_limits = functions.FunctionsLimits(timeout_minutes=60, cpu_cores=0.25, memory_gb=1, runtimes=[\"py39\"], response_size_mb=2)\n",
    "client = initialize_client(cdf_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.time_series.delete(external_id=\"VAL_17-FI-9101-286:VALUE.COPY\")\n",
    "# client.time_series.delete(external_id=\"CF_IdealPowerConsumption_NEW\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Inputs ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Required parameters\n",
    "- `ts_input_names` (list): \n",
    "    - names of input time series (a list, even if only one input). Must be given in same order as calculations are performed in `transformations.py`\n",
    "- `ts_output_names` (list): \n",
    "    - names of output time series (also given as list). NB: if multiple time series outputs, order of ts_output_names must correspond to order in ts_input_names.\n",
    "- `function_name` (string): \n",
    "    - name of Cognite Function to deploy (i.e., folder with name `cf_*function_name*`)\n",
    "- `calculation_function` (string): \n",
    "    - name of main calculation function to run, should be defined in transformation.py (in the folder `cf_*function_name*`) as `main_*calculation_function*`\n",
    "- `schedule_name` (string):\n",
    "    - name of schedule to set up for the Cognite Function. NB: make sure name is unique to avoid overwriting already existing schedules for a particular Cognite Function! If setting up multiple schedules for the same Cognite Function, one for each input time series, a good advice to keep them organized is to use the name of the time series as the name of the schedules \n",
    "- `aggregate` (dictionary):\n",
    "    - information about any aggregations to perform in the calculation.\n",
    "    - if **not** performing any aggregates, leave the dictionary empty!\n",
    "    - if performing aggregates, two keys must be specified:\n",
    "    1. `period` (string):\n",
    "        - the time range defining the aggregated period\n",
    "        - valid values: `[\"minute\", \"hour\", \"day\", \"month\", \"year\"]`\n",
    "    2. `type` (string):\n",
    "        - what type of aggregate to perform\n",
    "        - valid values: any aggregation supported by `pandas`, e.g., `\"mean\"`, `\"max\"`, ... \n",
    "- `sampling_rate` (int): \n",
    "    - sampling rate of input time series, given in seconds\n",
    "- `cron_interval_min` (string): \n",
    "    - minute-interval to run schedule at (NB: currently only supported for min-interval [1, 60)). The number should be provided as string.\n",
    "- `backfill_period` (int): \n",
    "    - the period (default: number of days) back in time to perform backfilling\n",
    "    - if performing aggregates, it is the number of aggregated periods (e.g., if aggregating over month, a value of 3 will backfill three month back in time)\n",
    "- `backfill_hour` (int):\n",
    "    - the hour of the day to perform backfilling\n",
    "- `backfill_min_start` (int):\n",
    "    - performs backfilling for any scheduled call that falls within hour=`backfill_hour` and minute=`[backfill_min_start, backfill_min_start+cron_interval_min]`\n",
    "- `testing` (bool):\n",
    "    - defaults to `False`. Set to `True` if running unit tests\n",
    "- `add_packages` (list): \n",
    "    - additional packages required to run the calculations in `transformations.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_input_names = [\"VAL_17-FI-9101-286:VALUE\", \"VAL_17-PI-95709-258:VALUE\", \"VAL_11-PT-92363B:X.Value\", \"VAL_11-XT-95067B:Z.X.Value\"] # Inputs to IdealPowerConsumption function # [\"VAL_11-XT-95067B:Z.X.Value\", 87.8, \"CF_IdealPowerConsumption\"] # Inputs to WasterEnergy function\n",
    "ts_input_names = [\"VAL_18-LIT-80243:VALUE\"]\n",
    "# ts_output_names = [\"CF_IdealPowerConsumption\"]\n",
    "ts_output_names = [\"VAL_18-LIT-80243.CDF.D.AVG.LeakValue\"]\n",
    "\n",
    "function_name = \"avg-drainage\"\n",
    "calculation_function = \"aggregate\"\n",
    "schedule_name = ts_input_names[0]\n",
    "\n",
    "aggregate = {}\n",
    "aggregate[\"period\"] = \"day\"\n",
    "aggregate[\"type\"] = \"mean\"\n",
    "\n",
    "sampling_rate = 60 #\n",
    "cron_interval_min = str(15) #\n",
    "assert int(cron_interval_min) < 60 and int(cron_interval_min) >= 1\n",
    "backfill_period = 3\n",
    "backfill_hour = 15 # 23\n",
    "backfill_min_start = 30\n",
    "\n",
    "add_packages = [\"statsmodels\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Optional parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tank_volume = 240\n",
    "derivative_value_excl = 0.002\n",
    "lowess_frac = 0.001\n",
    "lowess_delta = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insert parameters into data dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "backfill_min_start = min(59, backfill_min_start)\n",
    "\n",
    "data_dict = {'ts_input_names':ts_input_names,\n",
    "            'ts_output_names':ts_output_names,\n",
    "            'function_name': f\"cf_{function_name}\",\n",
    "            'schedule_name': schedule_name,\n",
    "            'calculation_function': f\"main_{calculation_function}\",\n",
    "            'granularity': sampling_rate,\n",
    "            'dataset_id': 1832663593546318, # Center of Excellence - Analytics dataset\n",
    "            'cron_interval_min': cron_interval_min,\n",
    "            'aggregate': aggregate,\n",
    "            'testing': False,\n",
    "            'backfill_period': backfill_period, # days by default (if not doing aggregates)\n",
    "            'backfill_hour': backfill_hour, # 23: backfilling to be scheduled at last hour of day as default\n",
    "            'backfill_min_start': backfill_min_start, 'backfill_min_end': min(59.9, backfill_min_start + int(cron_interval_min)),\n",
    "            'calc_params': {\n",
    "                'derivative_value_excl':derivative_value_excl, 'tank_volume':tank_volume,\n",
    "                'lowess_frac': lowess_frac, 'lowess_delta': lowess_delta, #'aggregate_period': aggregate[\"period\"]\n",
    "            }}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Instantiate Cognite Function ---\n",
    "\n",
    "Set up folder structure for the Cognite Function as required by the template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing __init__.py ...\n",
      "Writing handler.py ...\n",
      "Writing transformation.py ...\n",
      "Created requirements.txt in c:/Users/vetnev/OneDrive - Aker BP/Documents/First Task/opshub-task1/src/cf_power-Template\n",
      "Packages to add:  ['python-dotenv', 'pytest', 'cognite-sdk', 'ipykernel', 'pandas', 'numpy']\n",
      "\n",
      "Using version ^1.0.0 for python-dotenv\n",
      "\n",
      "Updating dependencies\n",
      "Resolving dependencies...\n",
      "\n",
      "Package operations: 1 install, 0 updates, 0 removals\n",
      "\n",
      "  â€¢ Installing python-dotenv (1.0.0)\n",
      "\n",
      "Writing lock file\n",
      "\n",
      "Using version ^7.4.4 for pytest\n",
      "\n",
      "Updating dependencies\n",
      "Resolving dependencies...\n",
      "\n",
      "Package operations: 5 installs, 0 updates, 0 removals\n",
      "\n",
      "  â€¢ Installing colorama (0.4.6)\n",
      "  â€¢ Installing iniconfig (2.0.0)\n",
      "  â€¢ Installing packaging (23.2)\n",
      "  â€¢ Installing pluggy (1.3.0)\n",
      "  â€¢ Installing pytest (7.4.4)\n",
      "\n",
      "Writing lock file\n",
      "\n",
      "Using version ^7.13.4 for cognite-sdk\n",
      "\n",
      "Updating dependencies\n",
      "Resolving dependencies...\n",
      "\n",
      "Package operations: 16 installs, 0 updates, 0 removals\n",
      "\n",
      "  â€¢ Installing pycparser (2.21)\n",
      "  â€¢ Installing cffi (1.16.0)\n",
      "  â€¢ Installing certifi (2023.11.17)\n",
      "  â€¢ Installing charset-normalizer (3.3.2)\n",
      "  â€¢ Installing cryptography (41.0.7)\n",
      "  â€¢ Installing idna (3.6)\n",
      "  â€¢ Installing urllib3 (2.1.0)\n",
      "  â€¢ Installing oauthlib (3.2.2)\n",
      "  â€¢ Installing pyjwt (2.8.0)\n",
      "  â€¢ Installing requests (2.31.0)\n",
      "  â€¢ Installing msal (1.26.0)\n",
      "  â€¢ Installing protobuf (4.25.2)\n",
      "  â€¢ Installing requests-oauthlib (1.3.1)\n",
      "  â€¢ Installing typing-extensions (4.9.0)\n",
      "  â€¢ Installing tzdata (2023.4)\n",
      "  â€¢ Installing cognite-sdk (7.13.4)\n",
      "\n",
      "Writing lock file\n",
      "\n",
      "Using version ^6.28.0 for ipykernel\n",
      "\n",
      "Updating dependencies\n",
      "Resolving dependencies...\n",
      "\n",
      "Package operations: 26 installs, 0 updates, 0 removals\n",
      "\n",
      "  â€¢ Installing six (1.16.0)\n",
      "  â€¢ Installing asttokens (2.4.1)\n",
      "  â€¢ Installing executing (2.0.1)\n",
      "  â€¢ Installing parso (0.8.3)\n",
      "  â€¢ Installing platformdirs (4.1.0)\n",
      "  â€¢ Installing pure-eval (0.2.2)\n",
      "  â€¢ Installing pywin32 (306)\n",
      "  â€¢ Installing traitlets (5.14.1)\n",
      "  â€¢ Installing wcwidth (0.2.13)\n",
      "  â€¢ Installing decorator (5.1.1)\n",
      "  â€¢ Installing jedi (0.19.1)\n",
      "  â€¢ Installing jupyter-core (5.7.1)\n",
      "  â€¢ Installing matplotlib-inline (0.1.6)\n",
      "  â€¢ Installing prompt-toolkit (3.0.43)\n",
      "  â€¢ Installing pygments (2.17.2)\n",
      "  â€¢ Installing python-dateutil (2.8.2)\n",
      "  â€¢ Installing pyzmq (25.1.2)\n",
      "  â€¢ Installing stack-data (0.6.3)\n",
      "  â€¢ Installing tornado (6.4)\n",
      "  â€¢ Installing comm (0.2.1)\n",
      "  â€¢ Installing debugpy (1.8.0)\n",
      "  â€¢ Installing ipython (8.20.0)\n",
      "  â€¢ Installing jupyter-client (8.6.0)\n",
      "  â€¢ Installing nest-asyncio (1.5.8)\n",
      "  â€¢ Installing psutil (5.9.7)\n",
      "  â€¢ Installing ipykernel (6.28.0)\n",
      "\n",
      "Writing lock file\n",
      "\n",
      "Using version ^2.1.4 for pandas\n",
      "\n",
      "Updating dependencies\n",
      "Resolving dependencies...\n",
      "\n",
      "Package operations: 3 installs, 0 updates, 0 removals\n",
      "\n",
      "  â€¢ Installing numpy (1.26.3)\n",
      "  â€¢ Installing pytz (2023.3.post1)\n",
      "  â€¢ Installing pandas (2.1.4)\n",
      "\n",
      "Writing lock file\n",
      "\n",
      "Using version ^1.26.3 for numpy\n",
      "\n",
      "Updating dependencies\n",
      "Resolving dependencies...\n",
      "\n",
      "No dependencies to install or update\n",
      "\n",
      "Writing lock file\n",
      "\n",
      "Installing dependencies from lock file\n",
      "\n",
      "No dependencies to install or update\n",
      "\n",
      "Created requirements.txt in c:/Users/vetnev/OneDrive - Aker BP/Documents/First Task/opshub-task1/src/cf_power-Template\n"
     ]
    }
   ],
   "source": [
    "generate_cf(function_name, add_packages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Define transformation function ---\n",
    "\n",
    "In this step, modify `transformation.py` to include your calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Deploy Cognite Function in one go ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single call\n",
    "\n",
    "Initial transformation is data-intensive. A scheduled call will likely time out. Instead, do a separate call first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cognite Function created. Waiting for deployment status to be ready ...\n",
      "Ready for deployement.\n",
      "Calling Cognite Function individually ...\n",
      "... Done\n"
     ]
    }
   ],
   "source": [
    "deploy_cognite_functions(data_dict, client,\n",
    "                         single_call=True, scheduled_call=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scheduled call\n",
    "\n",
    "For subsequent calls, transformations are only done on current date, not too data intensive. This can be handled by scheduled calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing schedule to start sharp at next minute ...\n",
      "Setting up Cognite Function schedule at time 2024-01-12 15:35:00+00:00 ...\n",
      "... Done\n"
     ]
    }
   ],
   "source": [
    "deploy_cognite_functions(data_dict, client,\n",
    "                         single_call=False, scheduled_call=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firsttask",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
