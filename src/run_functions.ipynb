{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook for deploying Cognite Function\n",
    "\n",
    "Run all cells sequentially until `Experimental` section to deploy your Cognite Function.\n",
    "\n",
    "Modifications are done in `Inputs` section, where you need to supply relevant input parameters as required by the calculations and deployment of your Cognite Function. The input parameters are stored in `data_dict`. There are two types of input parameters:\n",
    "- A: General parameters required for deployment of any Cognite Function\n",
    "- B: Optional (calculation-specific) parameters used as input to your calculation function. These should enter `data_dict[\"calc_params\"]` as key-value pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Required parameters\n",
    "- `ts_input_names`: names of input time series (given as list, even if only one input)\n",
    "- `ts_output_names`: names of output time series (also given as list). NB: if multiple time series outputs, order of ts_output_names must correspond to order in ts_input_names.\n",
    "- `function_name`: name of Cognite Function to deploy (i.e., folder with name `cf_*function_name*`)\n",
    "- `calculation_function`: name of calculation function to run, should be defined in transformation.py (in the folder `cf_*function_name*`) as `calc_*calculation_function*`\n",
    "- `sampling_rate`: sampling rate of input time series, given in seconds\n",
    "- `cron_interval_min`: minute-interval to run schedule at (NB: currently only supported for min-interval [1, 60))\n",
    "- `backfill_days`: number of days back in time to perform backfilling\n",
    "- `cdf_env`: CDF environment to deploy to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_input_names = [\"VAL_17-FI-9101-286:VALUE\", \"VAL_17-PI-95709-258:VALUE\", \"VAL_11-PT-92363B:X.Value\", \"VAL_11-XT-95067B:Z.X.Value\"]\n",
    "ts_input_names = [\"VAL_11-LT-95034A:X.Value\"]\n",
    "# ts_output_names = [\"VAL_17-FI-9101-286:MULTIPLE.Test\", \"VAL_17-PI-95709-258:MULTIPLE.Test\", \"VAL_11-PT-92363B:MULTIPLE.Test\", \"VAL_11-XT-95067B:MULTIPLE.Test\"]\n",
    "ts_output_names = [\"VAL_11-LT-95034A:X.CDF.D.AVG.LeakValue\"]\n",
    "function_name = \"daily-avg-drainage\" #\"multiple_outputs\"\n",
    "calculation_function = \"daily_avg_drainage\" # \"calculation\"\n",
    "\n",
    "sampling_rate = 60 #\n",
    "cron_interval_min = str(15) #\n",
    "assert int(cron_interval_min) < 60 and int(cron_interval_min) >= 1\n",
    "backfill_days = 3\n",
    "backfill_hour = 23\n",
    "backfill_min_start = 0\n",
    "\n",
    "cdf_env = \"dev\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Optional parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tank_volume = 1400\n",
    "derivative_value_excl = 0.002\n",
    "lowess_frac = 0.001\n",
    "lowess_delta = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insert parameters into data dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "backfill_min_end = backfill_min_start + int(cron_interval_min)\n",
    "if backfill_min_end >= 60:\n",
    "    backfill_min_end = 59\n",
    "\n",
    "data_dict = {'ts_input_names':ts_input_names,\n",
    "            'ts_output_names':ts_output_names,\n",
    "            'function_name': f\"cf_{function_name}\",\n",
    "            'calculation_function': f\"calc_{calculation_function}\",\n",
    "            'granularity': sampling_rate,\n",
    "            'dataset_id': 1832663593546318, # Center of Excellence - Analytics dataset\n",
    "            'backfill_days': backfill_days,\n",
    "            'backfill_hour': backfill_hour, # 23: backfilling to be scheduled at last hour of day as default\n",
    "            'backfill_min_start': backfill_min_start, 'backfill_min_end': backfill_min_end,\n",
    "            'calc_params': {\n",
    "                'derivative_value_excl':derivative_value_excl, 'tank_volume':tank_volume,\n",
    "                'lowess_frac': lowess_frac, 'lowess_delta': lowess_delta\n",
    "            }}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cognite.client.data_classes import functions\n",
    "\n",
    "from initialize import initialize_client\n",
    "from deploy_cognite_functions import deploy_cognite_functions\n",
    "\n",
    "func_suffix = \"Development\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set limit on function calls - don't think it's really necessary ...\n",
    "func_limits = functions.FunctionsLimits(timeout_minutes=60, cpu_cores=0.25, memory_gb=1, runtimes=[\"py39\"], response_size_mb=2)\n",
    "# I think that timeout_minutes will be capped at 15 anyway ...\n",
    "client = initialize_client(cdf_env, cache_token=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy Cognite Function in one go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single call\n",
    "\n",
    "Initial transformation is data-intensive. A scheduled call will likely time out. Instead, do a separate call first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cognite Function created. Waiting for deployment status to be ready ...\n",
      "Ready for deployement.\n",
      "Calling Cognite Function individually ...\n",
      "... Done\n"
     ]
    }
   ],
   "source": [
    "deploy_cognite_functions(data_dict, client, cron_interval_min,\n",
    "                         single_call=True, scheduled_call=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scheduled call\n",
    "\n",
    "For subsequent calls, transformations are only done on current date, not too data intensive. This can be handled by scheduled calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Cognite Function schedule ...\n",
      "... Done\n"
     ]
    }
   ],
   "source": [
    "deploy_cognite_functions(data_dict, client, cron_interval_min,\n",
    "                         single_call=False, scheduled_call=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sid = client.functions.schedules.list(function_id=func_drainage.id).to_pandas().id[0]\n",
    "scid = func_drainage.list_calls(schedule_id=sid, limit=-1).to_pandas()\n",
    "resp = func_drainage.retrieve_call(id=scid).get_response()\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "my_func = client.functions.retrieve(external_id=data_dict[\"function_name\"])\n",
    "my_schedule_id = client.functions.schedules.list(\n",
    "            name=data_dict[\"function_name\"]).to_pandas().id[0]\n",
    "all_calls = my_func.list_calls(\n",
    "            schedule_id=my_schedule_id, limit=-1).to_pandas()\n",
    "all_calls.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.date_range(start=datetime(2023,11,16,0,0), end=datetime(2023,11,16,3,51), freq=\"T\")\n",
    "extid = client.time_series.list(name=\"VAL_17-FI-9101-286:VALUE\")[0].external_id\n",
    "ts_orig_all = client.time_series.data.retrieve(external_id=extid,\n",
    "                                                   limit=20,\n",
    "                                                   ).to_pandas()\n",
    "ts_orig_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalizing Cognite Functions - sketch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ts_all = {\n",
    "        'ts_A': {'granularity':15, 'var':'a'},\n",
    "        'ts_B': {'granularity':10, 'b_specific':[1,2,3]},\n",
    "        'ts_X': {'max_days':8, 'thermo_coeff': 0.05, 'filter':'lowess'},\n",
    "        'ts_Y': {'tot_days': 40},\n",
    "        'out': 'test',\n",
    "        'in': {'granularity':15, 'b_specific':[1,2,3,4]},\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "func_drainage = client.functions.retrieve(external_id=\"draiange\")\n",
    "func_thermo = client.functions.retrieve(external_id=\"thermo\")\n",
    "\n",
    "func_drainage_schedule = []\n",
    "func_thermo_schedule = []\n",
    "\n",
    "\"\"\"Create individual schedules for three time series running drainage-Cognite-function\"\"\"\n",
    "for ts in ['A', 'B', 'Y']:\n",
    "    func_schedule = client.functions.schedules.create(\n",
    "        name=f\"avg-leak-{ts}\",\n",
    "        cron_expression=f\"*/{cron_interval_min} * * * *\",\n",
    "        function_id=func_drainage.id, # SAME function id\n",
    "        description=f\"Leak rate calculation for time series {ts}\",\n",
    "        data=ts_all[f'ts_{ts}'] # DIFFERENT data dictionaries\n",
    "    )\n",
    "    func_drainage_schedule.append(func_schedule)\n",
    "\n",
    "func_drainage_X = client.functions.schedules.create(\n",
    "    name=f\"avg-leak-X\",\n",
    "    cron_expression=f\"*/{cron_interval_min} * * * *\",\n",
    "    function_id=func_drainage.id,\n",
    "    description=f\"Leak rate calculation for time series X\",\n",
    "    data=ts_all['ts_X'],\n",
    ")\n",
    "\n",
    "\"\"\"Run schedules for DIFFERENT Cognite Functions on SAME time series Y.\n",
    "ALTERNATIVE 1: Each one with SAME data dictionary\"\"\"\n",
    "for func in [func_drainage, func_thermo]:\n",
    "    func_schedule = client.functions.schedules.create(\n",
    "        name=f\"tsY_{func.name}\",\n",
    "        cron_expression=f\"*/{cron_interval_min} * * * *\",\n",
    "        function_id=func.id, # DIFFERENT function ids\n",
    "        description=f\"{func.name} calculation for time series Y\",\n",
    "        data=ts_all['ts_Y'] # SAME data dictionary\n",
    "    )\n",
    "    func_thermo_schedule.append(func_schedule)\n",
    "\n",
    "\"\"\"ALTERNATIVE 2: Each one with DIFFERENT data dictionaries\"\"\"\n",
    "for func in [func_drainage, func_thermo]:\n",
    "    func_schedule = client.functions.schedules.create(\n",
    "        name=f\"tsY_{func.name}\",\n",
    "        cron_expression=f\"*/{cron_interval_min} * * * *\",\n",
    "        function_id=func.id, # DIFFERENT function ids\n",
    "        description=f\"{func.name} calculation for time series Y\",\n",
    "        data=ts_all[f'ts_Y'][func.name] # DIFFERENT data dictionaries\n",
    "    )\n",
    "    func_thermo_schedule.append(func_schedule)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firsttask",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
